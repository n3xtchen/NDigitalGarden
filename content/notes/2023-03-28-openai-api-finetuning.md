---
title: "2023-03-28"
date: 2023-03-28T18:19:00+08:00
tags:
- AI
---

**fine-tuning** ，字面意义是**微调**，在不改变 **GPT** 预训练模型的基础上，增加新的用例，重新训练让这个模型能够更加贴合实际使用场景。一般新增的用例数量都不会多，所以确实可以称为**微调**。

### fine-tuning 的目的

> 官方提供目的：
> - 比 **prompt** 设计更高质量的结果
> - 可以训练的示例比 prompt 能容纳的多 
> - 由于 prompt 更短，因此可以节省令牌，较低的延迟请求

通常情况，使用 **GPT**，系统会认为是一种对话，**GPT** 一般都会通过更多的解释；在实际算法任务中，一般只需要知道结果即可；举个例子：

```text
提问：
    情感分析：我今天把手机给摔了。

ChatGPT 的回答：
    根据您提供的信息，我认为您可能感到有些烦躁或沮丧。毕竟，手机是现代人生活中的重要工具之一，且可能是您的重要财产之一。如果您感到情绪上不安，可以尝试冷静下来并采取一些放松的措施，例如深呼吸、冥想或散步。如果您感到身体上受伤，请寻求医疗支持以确保自己的健康和安全。

# token 量：305
```

这是个情感分析的例子，而我想要的是：

```text
提问：
    情感分析：我今天把手机给摔了。

ChatGPT 的回答：
	负面

# token 量：39
```

这样子，输出更有指向性，而且可以节省更多的 [[notes/2023-03-10-gpt3-token|Token]]（将近 1/10）。

在**答案更明确**和**更低成本**（没有过多的解释）面前，**fine-tuning** 就具备了独特的魅力。

### fine-tuning 的具体场景

**fine-tuning** 可以解决各种各样的问题，最佳使用方式取决于你提供的具体用例。

下面是官方给出最常见的使用场景：

#### 分类问题（Classification）
在分类问题中，每一个 prompt 的输入都应该被分类成一个的预定义分类。对于这类问题，我们建议：

- 推理的时候，指定参数 `max-tokens`的值为 1；
- 训练的时候，每个分类不少于 100 个样本；
- 推理的时候，你可以指定 `logprobs=5` （5代表5个）获取每个类的估计概率；
- 用于微调的数据集在结构上和任务类型最好比较相似；



#### 条件生成（Conditional Generation）

条件生成问题指的是根据指定的输入生成指定的内容，包括释义、总结、实体提取、编写指定功能的产品描述、聊天机器人等等。对于这类问题，我们建议：

- 建议使用停止词，训练的样本 **completion** 增加一个**结尾词**（例如 end），推理的时候使用停止词参数，值和你训练样本的**结束词**一致（例如 `stop=[ "end" ]`）；
- 训练最好要有 500 个以上样本；
- 用于微调的数据集在结构上和任务类型最好比较相似；
- 确保样本的质量，并且遵循同样预期的格式；
- 训练的时候，使用更低的学习率和很少 epochs 数（可能只需要 1-2）对这里场景将会有更好的效果；