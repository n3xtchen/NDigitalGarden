---
title: "2023-03-28"
date: 2023-03-28T18:19:00+08:00
tags:
- AI
---

**fine-tuning** ，字面意义是**微调**，在不改变 **GPT** 预训练模型的基础上，增加新的用例，重新训练让这个模型能够更加贴合实际使用场景。一般新增的用例数量都不会多，所以确实可以称为**微调**。

### fine-tuning 的目的

> 官方提供目的：
> - 比 **prompt** 设计更高质量的结果
> - 可以训练的示例比 prompt 能容纳的多 
> - 由于 prompt 更短，因此可以节省令牌，较低的延迟请求

通常情况，使用 **GPT**，系统会认为是一种对话，**GPT** 一般都会通过更多的解释；在实际算法任务中，一般只需要知道结果即可；举个例子：

```text
提问：
    情感分析：我今天把手机给摔了。

ChatGPT 的回答：
    根据您提供的信息，我认为您可能感到有些烦躁或沮丧。毕竟，手机是现代人生活中的重要工具之一，且可能是您的重要财产之一。如果您感到情绪上不安，可以尝试冷静下来并采取一些放松的措施，例如深呼吸、冥想或散步。如果您感到身体上受伤，请寻求医疗支持以确保自己的健康和安全。

# token 量：305
```

这是个情感分析的例子，而我想要的是：

```text
提问：
    情感分析：我今天把手机给摔了。

ChatGPT 的回答：
	负面

# token 量：39
```

这样子，输出更有指向性，而且可以节省更多的 [[notes/2023-03-10-gpt3-token|Token]]（将近 1/10）。

在**答案更明确**和**更低成本**（没有过多的解释）面前，**fine-tuning** 就具备了独特的魅力。

### fine-tuning 的具体场景

**fine-tuning** 可以解决各种各样的问题，最佳使用方式取决于你提供的具体用例。

下面是官方给出最常见的使用场景：

#### 分类问题（Classification）
在分类问题中，每一个 prompt 的输入都应该被分类成一个的预定义分类。对于这种问题，我们推荐：

- 推理的时候，指定参数 `max-tokens`的值为 1；
- 每个分类不少于 100 个用例；
- 你可以
- 确保



#### 条件生成（Conditional Generation）

