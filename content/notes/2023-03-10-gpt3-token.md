---
title: "GPT：Token 介绍"
date: 2023-03-10T18:37:00
tags:
- AI
---

**Token** 可以被认为文本的基本组成单位，它可以是一个单词、一个标点符号或者一个词组，取决于分词器。

### openAI 的价格

> 官方的计价方式：[Pricing](https://openai.com/pricing)

| 模型类型      | 每1000个Tokens的费用($) | 说明 |
| ------------- | ----------------------- | ---- |
| gpt-3.5-turbo | 0.002                   | 最新==最强大最便宜==的对话模型，==推荐使用==      |
| Ada           | 0.0004                  |更适用于文本分类、命名实体识别和语义理解等任务      |
| Babbage       | 0.0005                  |      |
| Curie         | 0.002                   |      |
| Davinci       | 0.02                    | 最强（上一代）的 GPT3 的模型     |

### Token 的计量方式（==精准计量==）

首先，openAI 是==双向计费==的，包括你的提问内容和它的回答内容。并且提供了 **Token** 的工具：[OpenAI-tokenizer](https://platform.openai.com/tokenizer)，它可以对 token 进行精准的结算（chatgpt）。

然后，调用 API 的使用，返回的时候也会统计 **Token** 的使用量：

```
{
   "id":"chatcmpl-abc123",
   "object":"chat.completion",
   "created":1677858242,
   "model":"gpt-3.5-turbo-0301",
   "usage":{
      "prompt_tokens":13,      // 提问使用的 token 量
      "completion_tokens":7,   // 补齐使用的 token 量
      "total_tokens":20        // 总耗费的 token 量
   },
   "choices":[
     // ...
   ]
}
```

### 1000 Tokens 是什么概念？（粗略估算）

> 需要注意的是，这个数字仅仅是一个估算，具体的数字还可能会因为不同的上下文和语言模型而有所不同。

对于英文，官方也给出简洁的估算方式 [^1]:
- 1 token ~= 4 chars in English
- 1 token ~= ¾ words
- 100 tokens ~= 75 words
或者
- 1-2 sentence ~= 30 tokens
- 1 paragraph ~= 100 tokens
- 1,500 words ~= 2048 tokens

简单总结，就是 ==1000 Token 约等于750个英文单词==，67个句子，10个段落。

#### 对于中文，如何计算 Token 量？

在 **ChatGPT** 中，每个 **Token** 的长度并不是固定的，它们的长度是根据上下文和语言模型计算得出的。但是，对于一个通常长度的 **Token**，我们可以估算出大约需要多少个中文字符来达到相同的长度。

从官方文档可知，1000 Token 约等于 750 个英文单词，相当于 3000 个英文字符。根据一些研究的结果，英文单词的平均长度为 4 个字符，而中文单词的平均长度为 2 个汉字，那么==1000个token大约相当于1500个中文汉字==，150个句子（一般来说，一句话通常包含10个左右的汉字），另外一段话通常包含几个句子，其长度也会因文本类型、结构和主题而有所不同。

[^1]: [What are tokens and how to count them? | OpenAI Help Center](https://help.openai.com/en/articles/4936856-what-are-tokens-and-how-to-count-them)